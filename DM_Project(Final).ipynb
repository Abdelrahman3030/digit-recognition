{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f7937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ad11ef",
   "metadata": {},
   "source": [
    "# First Algorithm (DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1df7c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c874554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 0.2314 - accuracy: 0.9316\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0912 - accuracy: 0.9714\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0608 - accuracy: 0.9803\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0440 - accuracy: 0.9855\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0316 - accuracy: 0.9894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ddd60a88e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train) , (x_test, y_test) = mnist.load_data()   # lets Unpack that dataset to training and testing variables\n",
    "\n",
    "\n",
    "x_train = tf.keras.utils.normalize(x_train , axis=1)  # to normalize X train on axis 1\n",
    "x_test = tf.keras.utils.normalize(x_test , axis=1)     # to normalize X test on axis 1 \n",
    "Dnn_model = tf.keras.models.Sequential()                   # to build our network as FeedForward model \n",
    "Dnn_model.add(tf.keras.layers.Flatten(input_shape=(28,28)))                  # to add flatten layer in first layer which is (Input layer)\n",
    "Dnn_model.add(tf.keras.layers.Dense(256,activation=tf.nn.relu)) # Create first Hidden Layer with 256 neurons with Relu Function\n",
    "Dnn_model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))   # Create second Hidden Layer with 128 neurons with Relu Function \n",
    "Dnn_model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax)) # creating output layer with 10 neurons for range 10 to classify and with (Softmax) for (probability Distribution)\n",
    "Dnn_model.compile(optimizer='adam' , loss='sparse_categorical_crossentropy' , metrics=['accuracy'])  #to add your parameters\n",
    "Dnn_model.fit(x_train,y_train , epochs=5)  # to start train your Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fb2f362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0881 - accuracy: 0.9753\n",
      "DNN Validation Loss: 0.08805333822965622\n",
      "DNN Validation Accuracy: 0.9753000140190125\n"
     ]
    }
   ],
   "source": [
    "Dnn_val_loss , Dnn_val_acc = Dnn_model.evaluate(x_test, y_test)\n",
    "print(\"DNN Validation Loss:\", Dnn_val_loss)\n",
    "print(\"DNN Validation Accuracy:\", Dnn_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df80e245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: epic_num_reader.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: epic_num_reader.model\\assets\n"
     ]
    }
   ],
   "source": [
    "Dnn_model.save('epic_num_reader.model') # to save your parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9f155cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('epic_num_reader.model') # to load the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "511d259b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "[[5.69834006e-11 3.41461803e-10 1.07446297e-07 ... 9.99999523e-01\n",
      "  3.71107277e-11 9.71157519e-08]\n",
      " [7.46569690e-13 1.11528789e-04 9.99888301e-01 ... 6.27215224e-11\n",
      "  1.39012261e-12 8.83351444e-16]\n",
      " [1.01103081e-09 9.99988556e-01 2.57084110e-07 ... 5.89898991e-06\n",
      "  3.37059600e-06 4.37598935e-09]\n",
      " ...\n",
      " [2.46186513e-12 3.44533890e-09 1.22275556e-09 ... 4.25202842e-07\n",
      "  6.29230044e-07 5.49269537e-08]\n",
      " [7.04098446e-10 1.06072551e-09 1.28993413e-10 ... 5.61020705e-08\n",
      "  1.15921895e-04 4.91648458e-11]\n",
      " [3.52661178e-10 1.56201614e-11 5.57883566e-11 ... 8.27150143e-13\n",
      "  6.32336461e-10 4.90234752e-13]]\n"
     ]
    }
   ],
   "source": [
    "predictions = new_model.predict([x_test])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc9c0648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[6578])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c556fb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(predictions[6578]))  # to get the predicted value of index 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e10c592",
   "metadata": {},
   "source": [
    "# Second Algorithm (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "def7bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_Cnn = np.expand_dims(x_train, axis=-1)\n",
    "x_test_Cnn = np.expand_dims(x_test, axis=-1)\n",
    "Cnn_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation=tf.nn.relu, input_shape=[28,28,1]),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256,activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(128,activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73373d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cnn_model.compile(optimizer='adam' , loss='sparse_categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2dab49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 71s 37ms/step - loss: 0.1439 - accuracy: 0.9556\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 67s 36ms/step - loss: 0.0478 - accuracy: 0.9854\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 67s 36ms/step - loss: 0.0328 - accuracy: 0.9897\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 67s 36ms/step - loss: 0.0227 - accuracy: 0.9927\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 68s 36ms/step - loss: 0.0181 - accuracy: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ddffbd74f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cnn_model.fit(x_train_Cnn,y_train , epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9689092a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.0424 - accuracy: 0.9879\n",
      "CNN Validation Loss: 0.042433395981788635\n",
      "CNN Validation Accuracy: 0.9879000186920166\n"
     ]
    }
   ],
   "source": [
    "Cnn_val_loss , Cnn_val_acc = Cnn_model.evaluate(x_test_Cnn, y_test)\n",
    "print(\"CNN Validation Loss:\", Cnn_val_loss)\n",
    "print(\"CNN Validation Accuracy:\", Cnn_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa43baa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cnn_model.save_weights('CNN-MNIST.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3db53d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: epic_num_reader.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: epic_num_reader.model\\assets\n"
     ]
    }
   ],
   "source": [
    "Cnn_model.save('epic_num_reader.model') # to save your parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdcfe2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('epic_num_reader.model') # to load the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bba36f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step\n",
      "[[1.2679011e-13 2.2516489e-11 3.6696375e-11 ... 1.0000000e+00\n",
      "  7.2338047e-12 1.7535150e-08]\n",
      " [2.0534224e-04 1.2216398e-06 9.9978620e-01 ... 1.2223250e-06\n",
      "  1.7900115e-07 3.5297337e-08]\n",
      " [8.3382652e-08 9.9998283e-01 5.3986728e-08 ... 1.5008297e-06\n",
      "  1.3523716e-06 1.8075782e-07]\n",
      " ...\n",
      " [2.7560614e-12 1.3447378e-08 6.1415845e-10 ... 3.4361097e-08\n",
      "  9.0787950e-08 4.3060408e-07]\n",
      " [6.6555170e-09 1.8836286e-07 6.8872810e-11 ... 3.4909647e-10\n",
      "  1.3057604e-06 4.3284267e-08]\n",
      " [1.0525301e-03 2.0328805e-06 1.3843950e-06 ... 3.3244667e-08\n",
      "  3.1941192e-06 1.3202005e-06]]\n"
     ]
    }
   ],
   "source": [
    "predictions = new_model.predict([x_test])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "477ed665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[652])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e127339e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(predictions[652]))  # to get the predicted value of index 652"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bafe085",
   "metadata": {},
   "source": [
    "# Comparison Between The Two Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ead564aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN vs CNN Performance Comparison:\n",
      "DNN Validation Accuracy: 0.9753000140190125\n",
      "CNN Validation Accuracy: 0.9879000186920166\n"
     ]
    }
   ],
   "source": [
    "print(\"DNN vs CNN Performance Comparison:\")\n",
    "print(\"DNN Validation Accuracy:\", Dnn_val_acc)\n",
    "print(\"CNN Validation Accuracy:\", Cnn_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f7ce3",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61e16794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import cv2\n",
    "from PIL import ImageTk,Image,ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d63ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cnn_model.load_weights('CNN-MNIST.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fa2cff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "img = Image.new('RGB', (500, 500), (0, 0, 0))\n",
    "img_draw = ImageDraw.Draw(img)\n",
    "\n",
    "win = tk.Tk()\n",
    "\n",
    "canvas = tk.Canvas(win, width=500, height=500, bg='white')\n",
    "canvas.grid(row=0, column=0, columnspan=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3902374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_function(event):\n",
    "    \n",
    "    x=event.x\n",
    "    y=event.y\n",
    "    \n",
    "    x1=x-30\n",
    "    y1=y-30\n",
    "    \n",
    "    x2=x+30\n",
    "    y2=y+30\n",
    "\n",
    "    canvas.create_oval((x1,y1,x2,y2),fill='black')\n",
    "    img_draw.ellipse((x1,y1,x2,y2),fill='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ddd1074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save():\n",
    "    \n",
    "    global count\n",
    "    \n",
    "    img_array=np.array(img)\n",
    "    img_array = img_array[:, :, 0]\n",
    "    img_array = np.expand_dims(img_array, axis=-1)  # Add channel dimension\n",
    "    img_array = img_array / 255.0\n",
    "    img_array=img_array.reshape(1,28,28,1)\n",
    "    \n",
    "    cv2.imwrite(str(count)+'.jpg',img_array)\n",
    "    count=count+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfa08766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear():\n",
    "    \n",
    "    global img,img_draw\n",
    "    \n",
    "    canvas.delete('all')\n",
    "    img=Image.new('RGB',(500,500),(0,0,0))\n",
    "    img_draw=ImageDraw.Draw(img)    \n",
    "    \n",
    "    label_status.config(text='PREDICTED DIGIT: NONE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39b40f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "def predict():\n",
    "    \n",
    "    img_array=np.array(img)\n",
    "    img_array=cv2.cvtColor(img_array,cv2.COLOR_BGR2GRAY) # to convert to grayscale\n",
    "    img_array = cv2.resize(img_array, (28, 28))\n",
    "    img_array = np.expand_dims(img_array, axis=-1)  # Add channel dimension\n",
    "    img_array=img_array/255.0\n",
    "    img_array=img_array.reshape(1,28,28,1)\n",
    "    result=Cnn_model.predict(img_array)\n",
    "    label=np.argmax(result,axis=1)\n",
    "    \n",
    "    label_status.config(text='PREDICTED DIGIT:'+str(label))\n",
    "    \n",
    "count=0\n",
    "    \n",
    "win=tk.Tk()\n",
    "win.title(\"Digit Recognition\")\n",
    "\n",
    "canvas=tk.Canvas(win,width=500,height=500,bg='white')\n",
    "canvas.grid(row=0,column=0,columnspan=4)\n",
    "\n",
    "button_save=tk.Button(win,text='SAVE',bg='green',fg='white',font='Helvetica 20 bold',command=save)\n",
    "button_save.grid(row=1,column=0)\n",
    "\n",
    "button_predict=tk.Button(win,text='PREDICT',bg='blue',fg='white',font='Helvetica 20 bold',command=predict)\n",
    "button_predict.grid(row=1,column=1)\n",
    "\n",
    "button_clear=tk.Button(win,text='CLEAR',bg='yellow',fg='white',font='Helvetica 20 bold',command=clear)\n",
    "button_clear.grid(row=1,column=2)\n",
    "\n",
    "button_exit=tk.Button(win,text='EXIT',bg='red',fg='white',font='Helvetica 20 bold',command=win.destroy)\n",
    "button_exit.grid(row=1,column=3)\n",
    "\n",
    "label_status=tk.Label(win,text='PREDICTED DIGIT: NONE',bg='white',font='Helvetica 24 bold')\n",
    "label_status.grid(row=2,column=0,columnspan=4)\n",
    "\n",
    "canvas.bind('<B1-Motion>',event_function)\n",
    "img=Image.new('RGB',(500,500),(0,0,0))\n",
    "img_draw=ImageDraw.Draw(img)\n",
    "\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba0b436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
